{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c235b2a-dd7e-4ad0-8272-c9bb41f908a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -V  # 3.8.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c285c3a-4b98-4343-8caf-d777853e0785",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade \\\n",
    "    boto3==1.26.69 \\\n",
    "    flask==2.2.3 \\\n",
    "    mlflow==2.1.1 \\\n",
    "    numpy==1.20.3 \\\n",
    "    pandas==1.3.4 \\\n",
    "    sagemaker==2.132.0 \\\n",
    "    scikit-learn==0.24.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a449bc64-b63b-4a7e-bd74-55b851f25bb4",
   "metadata": {},
   "source": [
    "- install `awscli`\n",
    "- set up AWS credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aef8de-534e-4474-91db-11333181cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import pathlib\n",
    "import typing\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2654e00c-7242-4b08-b26d-b4ea058eaac2",
   "metadata": {},
   "source": [
    "# 1. log a model to mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df014af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_folder_path = pathlib.Path.cwd().absolute()\n",
    "mlflow_folder_path = current_folder_path / 'mlflow'\n",
    "mlflow_runs_folder_path = mlflow_folder_path / 'runs'\n",
    "\n",
    "mlflow_artifact_path = 'test'\n",
    "mlflow_registered_model_name = 'test-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed75f31-c080-4e0b-868b-b0d7bbd47d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(f'file://{mlflow_runs_folder_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c82516-28e4-45cf-bea0-ab3c9b7809da",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_size = 100\n",
    "features = np.random.rand(training_data_size, 3)\n",
    "labels = np.random.randint(0, 2, (training_data_size, 1))\n",
    "\n",
    "with mlflow.start_run():\n",
    "    rf_model = RandomForestClassifier()\n",
    "    rf_model.fit(features, labels)\n",
    "    mlflow.sklearn.log_model(rf_model, artifact_path=mlflow_artifact_path, registered_model_name=mlflow_registered_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0ea92e-989e-44ca-a2e8-7cd693410389",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95b8f89-1e1e-4655-a50c-9e3d08918f47",
   "metadata": {},
   "source": [
    "# 2. build and push an mlflow serving image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4ba97f-4cb4-4b42-a82e-32a61e7bef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_ecr_repository_name = 'mlflow-sm-serving'\n",
    "mlflow_ecr_image_tag = 'latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2884daf9-0580-457f-87d0-d9b397379869",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow sagemaker build-and-push-container --container $mlflow_ecr_repository_name --mlflow-home <path-to-mlflow-repo-folder>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9c1791-72b9-4993-9533-79f61f89d3a5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbac24b-d371-4568-a7d2-c651072f9c11",
   "metadata": {},
   "source": [
    "# 3. push the logged model to Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b67d7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_current_datetime_suffix(prefix: str) -> str:\n",
    "    current_datetime_str = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    return f'{prefix}-{current_datetime_str}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e64598-09e7-470f-97d4-499157642b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_account_id = <>\n",
    "aws_region = <>\n",
    "mlflow_inference_image_uri = f'{aws_account_id}.dkr.ecr.{aws_region}.amazonaws.com/{mlflow_ecr_repository_name}:{mlflow_ecr_image_tag}'\n",
    "execution_role_arn = <>\n",
    "output_s3_bucket_name = <>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ccc848-fe9c-4dd7-a1f1-4d00128bf069",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session(default_bucket=output_s3_bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e3702d-a31e-4af8-a786-ab4563fd2004",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_model_name = add_current_datetime_suffix(mlflow_registered_model_name)\n",
    "mlflow.sagemaker.push_model_to_sagemaker(\n",
    "    model_name=sagemaker_model_name,\n",
    "    model_uri=f'models:/{mlflow_registered_model_name}/latest',\n",
    "    execution_role_arn=execution_role_arn,\n",
    "    bucket=output_s3_bucket_name,\n",
    "    image_url=mlflow_inference_image_uri,\n",
    "    region_name=aws_region,\n",
    "    flavor='python_function',\n",
    ")\n",
    "\n",
    "sagemaker_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9e9b8c-b4da-43c3-b4b5-d2062ea8028e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_model_metadata = sagemaker_session.sagemaker_client.describe_model(ModelName=sagemaker_model_name)\n",
    "\n",
    "sagemaker_model_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c346807-c10b-44f8-8c91-8e43f85ece38",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8fea8e-7ca8-4628-b64e-58c2b42834b1",
   "metadata": {},
   "source": [
    "# 4. create & test a multi-container model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff675127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multi_container_sagemaker_model(\n",
    "        model_name: str,\n",
    "        containers: typing.List[dict],\n",
    "        inference_execution_mode: str,\n",
    "        role_arn: str,\n",
    "        sm_session: sagemaker.Session,\n",
    ") -> dict:\n",
    "    assert inference_execution_mode in {'Direct', 'Serial'}\n",
    "\n",
    "    response = sm_session.sagemaker_client.create_model(\n",
    "        ModelName=model_name,\n",
    "        Containers=containers,\n",
    "        InferenceExecutionConfig={'Mode': inference_execution_mode},\n",
    "        ExecutionRoleArn=role_arn,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def create_endpoint_config(\n",
    "        endpoint_config_name: str,\n",
    "        sm_model_name: str,\n",
    "        sm_session: sagemaker.Session,\n",
    "        instance_type: str = 'ml.m5.large',\n",
    "        instance_count: int = 1,\n",
    ") -> dict:\n",
    "    response = sm_session.sagemaker_client.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[\n",
    "            {\n",
    "                'VariantName': 'prod',\n",
    "                'ModelName': sm_model_name,\n",
    "                'InitialInstanceCount': instance_count,\n",
    "                'InstanceType': instance_type,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def create_endpoint(\n",
    "        endpoint_name: str,\n",
    "        endpoint_config_name: str,\n",
    ") -> dict:\n",
    "    response = sagemaker_session.sagemaker_client.create_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def invoke_endpoint(\n",
    "        endpoint_name: str,\n",
    "        inference_data: str,\n",
    "        sm_session: sagemaker.Session,\n",
    "        container_host_name: typing.Optional[str] = None,\n",
    "        request_content_type: str = 'application/json',\n",
    "        response_accept: str = 'application/json',\n",
    ") -> str:\n",
    "    request_args = dict(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType=request_content_type,\n",
    "        Accept=response_accept,\n",
    "        Body=inference_data,\n",
    "    )\n",
    "\n",
    "    if container_host_name is not None:\n",
    "        request_args['TargetContainerHostname'] = container_host_name\n",
    "\n",
    "\n",
    "    response = sm_session.sagemaker_runtime_client.invoke_endpoint(**request_args)\n",
    "\n",
    "    return response['Body'].read().decode()\n",
    "\n",
    "\n",
    "def delete_endpoint(\n",
    "        endpoint_name: str,\n",
    "        sm_session: sagemaker.Session,\n",
    "        endpoint_config_name: typing.Optional[str] = None,\n",
    "        sm_model_name: typing.Optional[str] = None,\n",
    "):\n",
    "    sm_session.sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "\n",
    "    if endpoint_config_name is not None:\n",
    "        sm_session.sagemaker_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "\n",
    "    if sm_model_name is not None:\n",
    "        sm_session.sagemaker_client.delete_model(ModelName=sm_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4c7414-1d56-4dbe-b900-afdef9e66fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_container_definition = {\n",
    "    'ContainerHostname': 'model-1',\n",
    "    'Image': sagemaker_model_metadata['PrimaryContainer']['Image'],\n",
    "    'ModelDataUrl': sagemaker_model_metadata['PrimaryContainer']['ModelDataUrl'],\n",
    "}\n",
    "\n",
    "second_container_definition = first_container_definition.copy()\n",
    "second_container_definition['ContainerHostname'] = 'model-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54035e61-bb5a-436f-bd87-64986796d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_container_model_name = add_current_datetime_suffix('mlflow-multi-container')\n",
    "create_model_response = create_multi_container_sagemaker_model(\n",
    "    model_name=multi_container_model_name,\n",
    "    containers=[first_container_definition, second_container_definition],\n",
    "    inference_execution_mode='Direct',\n",
    "    role_arn=execution_role_arn,\n",
    "    sm_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "create_model_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f0583a-ad04-4bde-92cb-f4c6bb1acb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_container_endpoint_config_name = add_current_datetime_suffix('mlflow-multi-container-config')\n",
    "endpoint_config_response = create_endpoint_config(\n",
    "    endpoint_config_name=multi_container_endpoint_config_name,\n",
    "    sm_model_name=multi_container_model_name,\n",
    "    sm_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "endpoint_config_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1df1667-9926-4be8-afca-a7a7ef2ec10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_container_endpoint_name = add_current_datetime_suffix('mlflow-multi-container-endpoint')\n",
    "endpoint_response = create_endpoint(\n",
    "    endpoint_name=multi_container_endpoint_name,\n",
    "    endpoint_config_name=multi_container_endpoint_config_name,\n",
    ")\n",
    "\n",
    "endpoint_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ec8653-76a4-44a8-b2c3-30ed6c3e5c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = invoke_endpoint(\n",
    "    endpoint_name=multi_container_endpoint_name,\n",
    "    inference_data=json.dumps({'dataframe_split': pd.DataFrame(features).to_dict(orient='split')}),\n",
    "    container_host_name=first_container_definition['ContainerHostname'],\n",
    "    sm_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "invoke_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f7e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = invoke_endpoint(\n",
    "    endpoint_name=multi_container_endpoint_name,\n",
    "    inference_data=json.dumps({'dataframe_split': pd.DataFrame(features).to_dict(orient='split')}),\n",
    "    container_host_name=second_container_definition['ContainerHostname'],\n",
    "    sm_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "invoke_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59233ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_endpoint(\n",
    "    endpoint_name=multi_container_endpoint_name,\n",
    "    endpoint_config_name=multi_container_endpoint_config_name,\n",
    "    sm_model_name=multi_container_model_name,\n",
    "    sm_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f9074d-f2d8-490f-94a1-2ed5eebda5bf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6b03da-b818-42cf-811f-3e9ef92ff8ac",
   "metadata": {},
   "source": [
    "# 5. create preprocessing \"model\" (script only) for an inference pipeline endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e04cd2a",
   "metadata": {},
   "source": [
    "prepare model inference code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfa9c6a-f112-42d6-9714-4abb782786d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts_folder_path = './scripts'\n",
    "processing_code_folder_path = f'{scripts_folder_path}/code'\n",
    "processing_script_name = 'inference.py'\n",
    "processing_script_path = f'{processing_code_folder_path}/{processing_script_name}'\n",
    "processing_model_archive_name = 'test-processing-model.tar.gz'\n",
    "processing_model_archive_path = f'./{processing_model_archive_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ecd8b6-3e4c-48bd-9b9b-499ed7f3ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $processing_code_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92a210a-941d-4af5-baba-05df9073d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $processing_script_path\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    return None\n",
    "\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    if request_content_type == 'application/json':\n",
    "        input_data = json.loads(request_body)\n",
    "        return input_data\n",
    "    else:\n",
    "        raise ValueError(f'Unsupported request content type: \"{request_content_type}\"')\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    return input_data\n",
    "\n",
    "\n",
    "def output_fn(prediction, content_type):\n",
    "    if content_type == 'application/json':\n",
    "        return json.dumps(prediction), content_type\n",
    "    else:\n",
    "        raise ValueError(f'Unsupported response content type: \"{content_type}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78105e55-aa47-44e4-9ebe-4c05b241c10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czvf $processing_model_archive_path -C $scripts_folder_path ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0841aca4-5100-44ab-a780-f97047a7f5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp $processing_model_archive_path s3://$output_s3_bucket_name/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9b305f-328f-4c09-95e7-f1327819abaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf $scripts_folder_path $processing_model_archive_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7c032a-aa1f-4658-9caf-e053cc6fd782",
   "metadata": {},
   "source": [
    "create a processing container definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72728032-6ee0-401d-8303-89689999d681",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_container_definition = {\n",
    "    'ContainerHostname': 'processing-model',\n",
    "    'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.0-1-cpu-py3',  # public image\n",
    "    'ModelDataUrl': f's3://{output_s3_bucket_name}/{processing_model_archive_name}',\n",
    "    'Environment': {\n",
    "        'SAGEMAKER_PROGRAM': processing_script_name,\n",
    "        'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/model/code',\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0372cda-2c2e-402f-bc2b-d3422a02748d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8668e388-587f-4b0c-aaa7-a837bdda71df",
   "metadata": {},
   "source": [
    "# 6. create an inference-pipeline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a15fd8-0d99-447a-b7b8-8ba0d8fd0de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_pipeline_model_name = add_current_datetime_suffix('mlflow-inference-pipeline')\n",
    "create_model_response = create_multi_container_sagemaker_model(\n",
    "    model_name=inference_pipeline_model_name,\n",
    "    containers=[processing_container_definition, second_container_definition],\n",
    "    inference_execution_mode='Serial',\n",
    "    role_arn=execution_role_arn,\n",
    "    sm_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "create_model_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009fe96f-6184-4f47-b2ef-cd14d50b1f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_pipeline_endpoint_config_name = add_current_datetime_suffix('mlflow-inference-pipeline-config')\n",
    "endpoint_config_response = create_endpoint_config(\n",
    "    endpoint_config_name=inference_pipeline_endpoint_config_name,\n",
    "    sm_model_name=inference_pipeline_model_name,\n",
    "    sm_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "endpoint_config_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989eddfc-5e2d-40cc-9dd8-97bf40c7a44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_pipeline_endpoint_name = add_current_datetime_suffix('mlflow-inference-pipeline-endpoint')\n",
    "endpoint_response = create_endpoint(\n",
    "    endpoint_name=inference_pipeline_endpoint_name,\n",
    "    endpoint_config_name=inference_pipeline_endpoint_config_name,\n",
    ")\n",
    "\n",
    "endpoint_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc425d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = invoke_endpoint(\n",
    "    endpoint_name=inference_pipeline_endpoint_name,\n",
    "    inference_data=json.dumps({'dataframe_split': pd.DataFrame(features).to_dict(orient='split')}),\n",
    "    sm_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "invoke_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ec0c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_endpoint(\n",
    "    endpoint_name=inference_pipeline_endpoint_name,\n",
    "    endpoint_config_name=inference_pipeline_endpoint_config_name,\n",
    "    sm_model_name=inference_pipeline_model_name,\n",
    "    sm_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2058e7-5ff8-4f44-a2f0-4844ddcae2e2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be83499-a591-4a42-ae94-19e383adedf3",
   "metadata": {},
   "source": [
    "# 7. multi-container endpoint with `nginx` disabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_container_non_nginx_definition = first_container_definition.copy()\n",
    "first_container_non_nginx_definition['Environment'] = {'DISABLE_NGINX': 'true'}\n",
    "\n",
    "second_container_non_nginx_definition = second_container_definition.copy()\n",
    "second_container_non_nginx_definition['Environment'] = {'DISABLE_NGINX': 'true'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ea2cc0-4d79-4540-a961-13c035b83858",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_container_non_nginx_model_name = add_current_datetime_suffix('mlflow-multi-container-nn')\n",
    "create_model_response = create_multi_container_sagemaker_model(\n",
    "    model_name=multi_container_non_nginx_model_name,\n",
    "    containers=[first_container_non_nginx_definition, second_container_non_nginx_definition],\n",
    "    inference_execution_mode='Direct',\n",
    "    role_arn=execution_role_arn,\n",
    "    sm_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "create_model_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083dc14f-986e-4d72-9365-e3d2cec23cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_container_non_nginx_endpoint_config_name = add_current_datetime_suffix('mlflow-multi-container-nn-config')\n",
    "endpoint_config_response = create_endpoint_config(\n",
    "    endpoint_config_name=multi_container_non_nginx_endpoint_config_name,\n",
    "    sm_model_name=multi_container_non_nginx_model_name,\n",
    "    sm_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "endpoint_config_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d859431a-d31b-41c9-aa03-38dccd538c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_container_non_nginx_endpoint_name = add_current_datetime_suffix('mlflow-multi-container-nn-endpoint')\n",
    "endpoint_response = create_endpoint(\n",
    "    endpoint_name=multi_container_non_nginx_endpoint_name,\n",
    "    endpoint_config_name=multi_container_non_nginx_endpoint_config_name,\n",
    ")\n",
    "\n",
    "endpoint_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63542fab-0255-4934-a9ec-c408a827f386",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = invoke_endpoint(\n",
    "    endpoint_name=multi_container_non_nginx_endpoint_name,\n",
    "    inference_data=json.dumps({'dataframe_split': pd.DataFrame(features).to_dict(orient='split')}),\n",
    "    container_host_name=first_container_non_nginx_definition['ContainerHostname'],\n",
    "    sm_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "invoke_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bebcde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = invoke_endpoint(\n",
    "    endpoint_name=multi_container_non_nginx_endpoint_name,\n",
    "    inference_data=json.dumps({'dataframe_split': pd.DataFrame(features).to_dict(orient='split')}),\n",
    "    container_host_name=second_container_non_nginx_definition['ContainerHostname'],\n",
    "    sm_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "invoke_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa16e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_endpoint(\n",
    "    endpoint_name=multi_container_non_nginx_endpoint_name,\n",
    "    endpoint_config_name=multi_container_non_nginx_endpoint_config_name,\n",
    "    sm_model_name=multi_container_non_nginx_model_name,\n",
    "    sm_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ef939b-dc44-459d-8b37-8a4c9292b4bf",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
